{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce3c6d6-43f5-42a6-9666-23632615ac48",
   "metadata": {},
   "source": [
    "# Medical Query Prototype \n",
    "\n",
    "## Description:\n",
    "As per the document: \"A prototype tool that allows users to query about medical drugs, search online medical news or research study sources via an API or any search strategies, index the relevant results, and use a Large Language Model (LLM) to summarize the information to answer the user's query.\"\n",
    "\n",
    "## Discussion: \n",
    "Suppose that we take medical papers and either (1) web-scrap relevant data (2) similarly scrap from a pdf, it would be preferable that our pipeline be a Question Answering system that can not only answer within a good accuracy but tell us when it cannot answer the query. For instance, if a common question is that of \"What are the main competitor drugs of [name] and what are their latest news now?\" If no such token allows for an answer we would want it to tell us so, essentially reading the paper for us. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d313bf2e-5064-4b9d-b254-32941bfa2e07",
   "metadata": {},
   "source": [
    "## Installation Instructions. (My machine is Ubuntu (Debian))\n",
    "1. <code> pip install llama-index <code>\n",
    "2. <code> pip install llama-index-readers-file <code>\n",
    "3. <code> pip install llama-index-readers-web <code>\n",
    "4. <code> pip install llama-index-embeddings-openai <code> OR <code> pip install llama-index-embeddings-huggingface <code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0438cac4-86ed-4173-a965-68cbbb8c90f4",
   "metadata": {},
   "source": [
    "# API Integration for News Search/API/PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2bc4a6-3f60-4de2-8b8e-8b2482cf5e75",
   "metadata": {},
   "source": [
    "## PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb56e37-8d8b-4168-8085-3969733daa4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Define our documents, LlamaIndex makes this particularly easy with it's Data Loaders on LlamaHub object and open source use.\n",
    "\n",
    "from llama_index.readers.file import PDFReader #We have a Data Loader for our PDF papers\n",
    "\n",
    "#PDF Loader\n",
    "pdf_loader = PDFReader()\n",
    "\n",
    "#Document Objects \n",
    "pdf_documents = pdf_loader.load_data(\"path/to/pdf/paper.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87028d6-43d6-4127-bd72-fe16bb8f5467",
   "metadata": {},
   "source": [
    "## Web Loader (News/Web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbd265-6c2e-4d46-95b1-5dbc78f0baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define our documents, LlamaIndex makes this particularly easy with it's Data Loaders on LlamaHub object and open source use.\n",
    "## This sort of web loader pattern can be extend towards News Sources instead of having a specific API for it. \n",
    "\n",
    "from llama_index.readers.web import BeautifulSoupWebReader #We have a Data Loader for a website (Note: This can potentially be difficult to do initially\n",
    "#and would require some other custom changes for dynamic sites, as well as sites that require logins and so forth, but this is a simple example.)\n",
    "\n",
    "#Web Loader\n",
    "web_loader = BeautifulSoupWebReader()\n",
    "\n",
    "#Document Objects \n",
    "web_documents = web_loader.load_data(urls=[URL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffa7e7c-3c77-4642-bdf9-840d482858e5",
   "metadata": {},
   "source": [
    "## Web Scraper (Example on website)\n",
    "\n",
    "This would be an example of how to create a simple webscraper for a more specialized website, one in which we must use the CSS selectors or XML paths to get specific data. This web scraper employs the use of playwright. (EDIT FINISH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654c421d-81db-450c-8411-7eb7f666e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WEB SCRAPING CELL: \n",
    "from playwright.async_api import async_playwright\n",
    "import asyncio\n",
    "\n",
    "async def process_locator(locator):\n",
    "    count = await locator.count()\n",
    "    if count > 1: #We have many elements and must resolve each inner text\n",
    "        texts = \"\"\n",
    "        for i in range(count):\n",
    "            element = locator.nth(i)\n",
    "            if await element.is_visible():\n",
    "                inner_text = await element.inner_text()\n",
    "                texts = texts + \",\" + inner_text\n",
    "                return texts\n",
    "    else:\n",
    "        if await locator.is_visible():\n",
    "            return await locator.inner_text()\n",
    "        else:\n",
    "            return \"NA\"\n",
    "    \n",
    "\n",
    "async def main():\n",
    "   async with async_playwright() as pw:\n",
    "       browser = await pw.chromium.launch(\n",
    "           ##We'll employ the use of chromium for this webscraper\n",
    "           ##Using a proxy creates HTTP errors.\n",
    "          headless=False\n",
    "      )\n",
    "\n",
    "       #Beginning page: \n",
    "       page = await browser.new_page()\n",
    "       await page.goto('https://world.openfoodfacts.org/')\n",
    "       await page.wait_for_timeout(5000)\n",
    "       result = []\n",
    "       food_urls = []\n",
    "       food_list = await page.query_selector_all('.list_product_a')\n",
    "       for food in food_list:\n",
    "           food_urls.append(await food.get_attribute('href'))\n",
    "           \n",
    "       for food_url in food_urls:\n",
    "            food_info = {}\n",
    "            await page.goto(food_url)\n",
    "            #Title: \n",
    "            title = page.locator(\".title-1\")\n",
    "            food_info['title'] = await process_locator(title)\n",
    "            #Common Name:\n",
    "            common_name = page.locator(\"#field_generic_name_value\")\n",
    "            food_info['common_name'] = await process_locator(common_name)\n",
    "            #Quantity:\n",
    "            quantity = page.locator(\"#field_quantity_value\")\n",
    "            food_info['quantity'] = await process_locator(quantity)\n",
    "            #Packaging: \n",
    "            packaging = page.locator(\"#field_packaging_value\")\n",
    "            food_info['packaging'] = await process_locator(packaging)\n",
    "            #Brands:\n",
    "            brand = page.locator(\"#field_brands_value\")\n",
    "            food_info['brand'] = await process_locator(brand)\n",
    "            #Categories:\n",
    "            categories = page.locator(\"#field_categories_value\")\n",
    "            food_info['categories'] = await process_locator(categories)\n",
    "            #Certifications:\n",
    "            certifications = page.locator(\"#field_labels_value\")\n",
    "            food_info['certifications'] = await process_locator(certifications)\n",
    "            #Origin:\n",
    "            origin = page.locator(\"#field_origin_value\")\n",
    "            food_info['origin'] = await process_locator(origin)\n",
    "            #origin of ingredients:\n",
    "            origin_of_ingredients = page.locator(\"#field_origins_value\")\n",
    "            food_info['origin_of_ingredients'] = await process_locator(origin_of_ingredients)\n",
    "            #Places of manufacturing:\n",
    "            places_manufactured = page.locator(\"#field_manufacturing_places_value\")\n",
    "            food_info['places_manufactured'] = await process_locator(places_manufactured)\n",
    "            #Stores:\n",
    "            stores = page.locator(\"#field_stores_value\")\n",
    "            food_info['stores'] = await process_locator(stores)\n",
    "            #Countries where Sold:\n",
    "            countries_sold = page.locator(\"#field_countries_value\")\n",
    "            food_info['countries_sold'] = await process_locator(countries_sold)\n",
    "           \n",
    "            #HEALTH SECTION\n",
    "            #Notice, because of the increasing complexity of the DOM elements in this area the CSS selectors don't follow a similarly nice pattern\n",
    "            #Ingredients: \n",
    "            ingredients = page.locator(\"#panel_ingredients_content .panel_text\")\n",
    "            food_info['ingredients'] = await process_locator(ingredients)\n",
    "            #NOVA score:\n",
    "            nova_score = page.locator(\"ul#panel_nova li.accordion-navigation h4\")\n",
    "            food_info['nova_score'] = await process_locator(nova_score)\n",
    "            # #Palm Status:\n",
    "            # palm_status = page.locator(\".accordion-navigation active .content panel_content active .panel_text\")\n",
    "            # food_info['palm_status'] = await process_locator(palm_status)\n",
    "            # #Vegan Status:\n",
    "            # vegan_status = page.locator(\"#panel_ingredients_analysis_en-vegan_content .panel_text\")\n",
    "            # food_info['vegan_status'] = await process_locator(vegan_status)\n",
    "            # #Vegetarian Status:\n",
    "            # vegetarian_status = page.locator(\"#panel_ingredients_analysis_en-vegetarian_content .panel_text\")\n",
    "            # food_info['vegetarian_status'] = await process_locator(vegetarian_status)\n",
    "            #Nutrition grade:\n",
    "            nutrition_grade = page.locator(\".accordion-navigation .grade_a_title\")\n",
    "            food_info['nutrition_grade'] = await process_locator(nutrition_grade)\n",
    "\n",
    "            # #NUTITRION FACTS\n",
    "            # #\n",
    "            # table_rows = await page.query_selector_all(\"#panel_nutrition_facts_table_content\")\n",
    "            # nutrition_facts = {}\n",
    "            # for row in table_rows:\n",
    "            #     columns = await row.query_selector_all('td')\n",
    "            #     name = await process_locator(columns[0])\n",
    "            #     value_per_100g = await process_locator(columns[1])\n",
    "            #     nutrition_facts[name] = {\n",
    "            #         \"100g/100ml\": value_per_100g\n",
    "            #     }\n",
    "                    \n",
    "                    \n",
    "            # food_info['nutrition_table'] = nutrition_facts\n",
    "            result.append(food_info)\n",
    "            \n",
    "\n",
    "\n",
    "       \n",
    "       \n",
    "\n",
    "       \n",
    "           \n",
    "           \n",
    "           \n",
    "       await browser.close()\n",
    "       return result\n",
    "if __name__ == '__main__':\n",
    "   result = await main()\n",
    "\n",
    "#Problems & Changes:\n",
    "#\n",
    "\n",
    "#CITATIONs: \n",
    "#Code cited from OxyLabs: https://github.com/oxylabs/playwright-web-scraping?tab=readme-ov-file\n",
    "#,https://playwright.dev/python/docs/locat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e565ed3-6891-498d-a917-e8a8c2d27a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenated the documents\n",
    "\n",
    "documents = pdf_documents + web_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a21a0-700f-4bb1-92fe-329650c0962c",
   "metadata": {},
   "source": [
    "# Information Indexing & Relevance Filtering \n",
    "\n",
    "For this task, we employ the use of Retrieval Augmented Generation (RAG). Note that I am choosing this over fine-tuning at this moment due to the time constraint. Fine-tuning a specific open source model on Hugging Face, for example, could provide accurate results for a QA system, but is generally more expensive of a procedure. Additionally, fine-tuning provides a more static model, and requires a \"re fine-tuning\" with every new dataset. whereas RAG is more dynamic.\n",
    "\n",
    "RAG's essentially work by creating a data structure (embeddings) of our documents, and allowing our LLM to more or less mathematically provide an answer to our query based on the vector embeddings of both. A particularly good library for RAG is LlamaIndex. Note: At this point we assume to have the pdfs and relevant websites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7461a-2969-40a3-8f7a-f306c5b8e356",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "We then take our documents and return vector emebeddings, allowing for a data structure that allows our LLMs to query the data. For this procedure we can employ the use of LLM's to embedded our data, OpenSource (HuggingFace) and OpenAI llms provide this functionality. Notice, in the Installation Instructions I provided a choice for both, this is the case as an API key is required for OpenAI use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e0b6b-d79f-45ef-95f7-253135a24ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OpenAI usage: \n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# global\n",
    "Settings.embed_model = OpenAIEmbedding()\n",
    "\n",
    "# per-index\n",
    "index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b0ba9-478b-4509-8653-7f8fa71e6ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Hugging Face usage (bge-small-en-v1.5):\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n",
    "# per-index\n",
    "index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb96e817-752d-4936-80f6-20a32d7cd9fd",
   "metadata": {},
   "source": [
    "# Retriever \n",
    "\n",
    "Retrievers objects allow us to get the most relevant answer given a query. As such, this is a possible method to **Relevance Filtering**. For this, we use the VectorIndexRetriever. (Note: There are many selections and preferences for retriever) The retriever allows for fetching the maximum relevant context for our query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d07165-3eb2-496b-b512-b1debb221c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=2,\n",
    ")\n",
    "\n",
    "# configure response synthesizer (We use the default response synthesizer)\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21015cb-1c46-4735-9c33-dc97d38d6103",
   "metadata": {},
   "source": [
    "## Query by LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eae7e3d-5bb1-4893-8ae0-973b57c7cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "# query\n",
    "response = query_engine.query(\"What are the main competitor drugs of [drug name] and what are their latest news now?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ee808-5c45-48a5-b5bd-756bf042b6f8",
   "metadata": {},
   "source": [
    "![title](img/basic_rag.png)\n",
    "\n",
    "\n",
    "High-level RAG image cited from Llama Index: https://docs.llamaindex.ai/en/stable/getting_started/concepts/#indexing-stage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
